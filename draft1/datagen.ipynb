{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clothing ID, Brand, Category, Color, .... \n",
    "#User ID, Clothing ID, Rating (0 = Disike,1 = Like,2 = Love,3 = Purhcased...)\n",
    "\n",
    "#Method: \n",
    "#Collaborative Filtering, Epsilon Greedy Algorithm (Q Learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files generated successfully: clothing.csv and user_ratings.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Parameters\n",
    "num_clothing = 500\n",
    "num_users = 1000\n",
    "num_ratings = 10000\n",
    "\n",
    "# Clothing data generation\n",
    "clothing_id = [f\"{i:05d}\" for i in range(1, num_clothing + 1)]\n",
    "brands = ['Brand' + str(i) for i in range(1, 21)]  # 20 random brand names\n",
    "categories = ['shoes', 'shirts', 'pants', 'shorts', 'jackets', 'hoodies', 'hats']\n",
    "colors = ['red', 'blue', 'green', 'black', 'white', 'yellow', 'purple', 'grey', 'orange', 'brown']\n",
    "\n",
    "clothing_data = pd.DataFrame({\n",
    "    'Clothing ID': clothing_id,\n",
    "    'Clothing Brand': random.choices(brands, k=num_clothing),\n",
    "    'Category': random.choices(categories, k=num_clothing),\n",
    "    'Color': random.choices(colors, k=num_clothing)\n",
    "})\n",
    "\n",
    "# User ratings data generation\n",
    "user_ids = [f\"{i:04d}\" for i in range(1, num_users + 1)]\n",
    "clothing_ids = random.choices(clothing_id, k=num_ratings)\n",
    "ratings = np.random.randint(0, 3, size=num_ratings)\n",
    "\n",
    "user_ratings_data = pd.DataFrame({\n",
    "    'User ID': random.choices(user_ids, k=num_ratings),\n",
    "    'Clothing ID': clothing_ids,\n",
    "    'Rating': ratings\n",
    "})\n",
    "\n",
    "# Save to CSV\n",
    "clothing_data.to_csv('clothing.csv', index=False)\n",
    "user_ratings_data.to_csv('user_ratings.csv', index=False)\n",
    "\n",
    "print(\"Files generated successfully: clothing.csv and user_ratings.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>Clothing ID</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0069</td>\n",
       "      <td>00018</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1603</td>\n",
       "      <td>00050</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4625</td>\n",
       "      <td>00512</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0162</td>\n",
       "      <td>00711</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4450</td>\n",
       "      <td>00097</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43128</th>\n",
       "      <td>6542</td>\n",
       "      <td>00143</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43129</th>\n",
       "      <td>5118</td>\n",
       "      <td>00715</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43130</th>\n",
       "      <td>2941</td>\n",
       "      <td>00490</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43131</th>\n",
       "      <td>0246</td>\n",
       "      <td>00116</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43132</th>\n",
       "      <td>5421</td>\n",
       "      <td>00642</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43133 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      User ID Clothing ID  Rating\n",
       "0        0069       00018       1\n",
       "1        1603       00050       1\n",
       "2        4625       00512       2\n",
       "3        0162       00711       2\n",
       "4        4450       00097       2\n",
       "...       ...         ...     ...\n",
       "43128    6542       00143       2\n",
       "43129    5118       00715       1\n",
       "43130    2941       00490       0\n",
       "43131    0246       00116       0\n",
       "43132    5421       00642       1\n",
       "\n",
       "[43133 rows x 3 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Simulate data creation\n",
    "def create_data():\n",
    "    num_clothing = 754\n",
    "    num_users = 10000\n",
    "    num_ratings = 43133\n",
    "\n",
    "    # Clothing data\n",
    "    clothing_id = [f\"{i:05d}\" for i in range(1, num_clothing + 1)]\n",
    "    brands = ['Brand' + str(i) for i in range(1, 21)]  # 20 brands\n",
    "    categories = ['shoes', 'shirts', 'pants', 'shorts', 'jackets', 'hoodies', 'hats']\n",
    "    colors = ['red', 'blue', 'green', 'black', 'white', 'yellow', 'purple', 'grey', 'orange', 'brown']\n",
    "\n",
    "    clothing_data = pd.DataFrame({\n",
    "        'Clothing ID': clothing_id,\n",
    "        'Clothing Brand': random.choices(brands, k=num_clothing),\n",
    "        'Category': random.choices(categories, k=num_clothing),\n",
    "        'Color': random.choices(colors, k=num_clothing)\n",
    "    })\n",
    "\n",
    "    # User ratings data\n",
    "    user_ids = [f\"{i:04d}\" for i in range(1, num_users + 1)]\n",
    "    ratings = np.random.randint(0, 3, size=num_ratings)\n",
    "\n",
    "    user_ratings_data = pd.DataFrame({\n",
    "        'User ID': random.choices(user_ids, k=num_ratings),\n",
    "        'Clothing ID': random.choices(clothing_id, k=num_ratings),\n",
    "        'Rating': ratings\n",
    "    })\n",
    "\n",
    "    return clothing_data, user_ratings_data\n",
    "\n",
    "# Call the function to create data\n",
    "clothing_data, user_ratings_data = create_data()\n",
    "\n",
    "\n",
    "user_ratings_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Training Loss: 21.5966396892772\n",
      "Epoch 2: Training Loss: 12.170845845166374\n",
      "Epoch 3: Training Loss: 7.363084905287799\n",
      "Epoch 4: Training Loss: 4.603492978741141\n",
      "Epoch 5: Training Loss: 2.9698950087322906\n",
      "Epoch 6: Training Loss: 1.9651107788085938\n",
      "Epoch 7: Training Loss: 1.3211447394946043\n",
      "Epoch 8: Training Loss: 0.9052712207331377\n",
      "Epoch 9: Training Loss: 0.6216573719592655\n",
      "Epoch 10: Training Loss: 0.43448316174394946\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Convert user IDs and clothing IDs to categorical indices\n",
    "user_ids = user_ratings_data['User ID'].astype('category')\n",
    "clothing_ids = user_ratings_data['Clothing ID'].astype('category')\n",
    "\n",
    "# Create mappings\n",
    "user_map = {user_id: i for i, user_id in enumerate(user_ids.cat.categories)}\n",
    "clothing_map = {clothing_id: i for i, clothing_id in enumerate(clothing_ids.cat.categories)}\n",
    "\n",
    "# Update data with mapped values\n",
    "user_ratings_data['User ID'] = user_ids.cat.codes\n",
    "user_ratings_data['Clothing ID'] = clothing_ids.cat.codes\n",
    "\n",
    "# Split data\n",
    "train_data, test_data = train_test_split(user_ratings_data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Dataset class\n",
    "class RatingsDataset(Dataset):\n",
    "    def __init__(self, user_ratings):\n",
    "        self.users = torch.tensor(user_ratings['User ID'].values, dtype=torch.long)\n",
    "        self.items = torch.tensor(user_ratings['Clothing ID'].values, dtype=torch.long)\n",
    "        self.ratings = torch.tensor(user_ratings['Rating'].values, dtype=torch.float32)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.ratings)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.users[idx], self.items[idx], self.ratings[idx]\n",
    "\n",
    "# Define the model\n",
    "class MatrixFactorization(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embedding_size=20):\n",
    "        super(MatrixFactorization, self).__init__()\n",
    "        self.user_embeddings = nn.Embedding(num_users, embedding_size)\n",
    "        self.item_embeddings = nn.Embedding(num_items, embedding_size)\n",
    "        self.user_biases = nn.Embedding(num_users, 1)\n",
    "        self.item_biases = nn.Embedding(num_items, 1)\n",
    "        \n",
    "    def forward(self, user, item):\n",
    "        user_embedding = self.user_embeddings(user)\n",
    "        item_embedding = self.item_embeddings(item)\n",
    "        user_bias = self.user_biases(user)\n",
    "        item_bias = self.item_biases(item)\n",
    "        \n",
    "        # Dot product of user and item embeddings\n",
    "        interaction = (user_embedding * item_embedding).sum(dim=1)\n",
    "        \n",
    "        # Add biases\n",
    "        interaction += user_bias.squeeze() + item_bias.squeeze()\n",
    "        \n",
    "        return interaction\n",
    "\n",
    "# Instantiate the model\n",
    "num_users = user_ids.cat.categories.size\n",
    "num_items = clothing_ids.cat.categories.size\n",
    "model = MatrixFactorization(num_users, num_items)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Load data into DataLoader\n",
    "train_dataset = RatingsDataset(train_data)\n",
    "test_dataset = RatingsDataset(test_data)\n",
    "train_loader = DataLoader(train_dataset, batch_size=512, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=512, shuffle=False)\n",
    "\n",
    "# Training loop\n",
    "def train(epoch, model, train_loader, loss_fn, optimizer):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for user, item, rating in train_loader:\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        prediction = model(user, item)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = loss_fn(prediction, rating)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    print(f'Epoch {epoch}: Training Loss: {total_loss / len(train_loader)}')\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 10\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    train(epoch, model, train_loader, loss_fn, optimizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 11.9881742477417\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Function to generate random data\n",
    "def generate_random_data(num_items, num_users, num_ratings):\n",
    "    clothing_ids = [f\"{i:05d}\" for i in range(1, num_items + 1)]\n",
    "    user_ids = [f\"{i:04d}\" for i in range(1, num_users + 1)]\n",
    "    ratings = np.random.randint(0, 3, size=num_ratings)\n",
    "    \n",
    "    random_data = pd.DataFrame({\n",
    "        'User ID': random.choices(user_ids, k=num_ratings),\n",
    "        'Clothing ID': random.choices(clothing_ids, k=num_ratings),\n",
    "        'Rating': ratings\n",
    "    })\n",
    "    return random_data\n",
    "\n",
    "# Create new random test data\n",
    "new_test_data = generate_random_data(500, 1000, 5000)\n",
    "\n",
    "# Assuming the model and other variables have been defined in the earlier script:\n",
    "# Convert this new test data\n",
    "new_test_user_ids = new_test_data['User ID'].astype('category')\n",
    "new_test_clothing_ids = new_test_data['Clothing ID'].astype('category')\n",
    "new_test_data['User ID'] = new_test_user_ids.cat.codes\n",
    "new_test_data['Clothing ID'] = new_test_clothing_ids.cat.codes\n",
    "\n",
    "# Create a Dataset and DataLoader for the new test data\n",
    "new_test_dataset = RatingsDataset(new_test_data)\n",
    "new_test_loader = DataLoader(new_test_dataset, batch_size=512, shuffle=False)\n",
    "\n",
    "# Function to evaluate the model\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for user, item, rating in test_loader:\n",
    "            prediction = model(user, item)\n",
    "            loss = loss_fn(prediction, rating)\n",
    "            total_loss += loss.item()\n",
    "    print(f\"Test Loss: {total_loss / len(test_loader)}\")\n",
    "\n",
    "# Evaluate the model on the new test data\n",
    "evaluate_model(model, new_test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
